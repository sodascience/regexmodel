{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a96173cf",
   "metadata": {},
   "source": [
    "# Tutorial on regexmodel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52e532f",
   "metadata": {},
   "source": [
    "## Setup and installation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bcc3f78",
   "metadata": {},
   "source": [
    "If you haven't installed `regexmodel` yet, including the optional dependencies, do so now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "881dd17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install git+https://github.com/sodascience/regexmodel.git[tutorial]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b748a354",
   "metadata": {},
   "source": [
    "Normally we would already have data that we want to model and synthesize, but for this tutorial we will use the faker package to generate that data for us. We will use fake email addresses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "85dbeb0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from faker import Faker\n",
    "from regexmodel.util import Dir\n",
    "from regexmodel.datastructure import BaseRegex\n",
    "from regexmodel.model2 import RegexModel\n",
    "from regexmodel.model import RegexModel as OldRegexModel\n",
    "from regexmodel.data2 import RegexNode, OrNode, Edge\n",
    "import polars as pl\n",
    "\n",
    "fake = Faker(\"nl\")\n",
    "Faker.seed(12345)\n",
    "email_addresses = pl.Series([fake.ipv4() for _ in range(4000)])\n",
    "series = email_addresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d79b1dd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'failed': 0, 'success': 4000, 'n_tot_char': 52985, 'n_char_success': 52985, 'n_parameters': 8, 'avg_log_like_per_char': -2.112847912712068, 'avg_log_like_pc_success': -2.112847912712068}\n"
     ]
    }
   ],
   "source": [
    "model = RegexModel.fit(email_addresses, count_thres=20)\n",
    "old_model = OldRegexModel.fit(email_addresses, count_thres=20)\n",
    "print(model.fit_statistics(email_addresses))\n",
    "#print(old_model.fit_statistics(email_addresses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "01030d98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[0-9]{1,3}[.][0-9]{1,3}[.][0-9]{1,3}[.][0-9]{1,3}'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "55c319f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'225.5.517.3'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9492156e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def _get_bounds(key, count_dict, count_thres, sigma, tot_counts):\n",
    "    if key in count_dict:\n",
    "        lower_bound = (count_dict[key] - sigma*np.sqrt(count_thres))/tot_counts\n",
    "        upper_bound = (count_dict[key] + sigma*np.sqrt(count_thres))/tot_counts\n",
    "    else:\n",
    "        lower_bound = 0\n",
    "        upper_bound = (count_thres + sigma*np.sqrt(count_thres))/tot_counts\n",
    "    return lower_bound, upper_bound\n",
    " \n",
    "\n",
    "def _check_stat_compatible(stat_a, stat_b, count_thres, sigma=3):\n",
    "    dict_stat_a = {regex._base_regex: len(series)-series.null_count() for regex, score, series in stat_a}\n",
    "    dict_stat_b = {regex._base_regex: len(series)-series.null_count() for regex, score, series in stat_b}\n",
    "    tot_a = np.sum([x for x in dict_stat_a.values()])\n",
    "    tot_b = np.sum([x for x in dict_stat_b.values()])\n",
    "    for key in (set(dict_stat_a) | set(dict_stat_b)):\n",
    "        lower_a, upper_a = _get_bounds(key, dict_stat_a, count_thres, sigma, tot_a)\n",
    "        lower_b, upper_b = _get_bounds(key, dict_stat_b, count_thres, sigma, tot_b)\n",
    "        print(key, lower_a, upper_a, lower_b, upper_b)\n",
    "        if lower_a > upper_b or lower_b > upper_a:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "edd5083c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'OrRegex' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mstring\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28misinstance\u001b[39m(\u001b[43mOrRegex\u001b[49m([]), BaseRegex)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'OrRegex' is not defined"
     ]
    }
   ],
   "source": [
    "import string\n",
    "isinstance(OrRegex([]), BaseRegex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eefa30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from regexmodel.regexclass2 import UpperRegex, LowerRegex, DigitRegex, score_single, LiteralRegex, OrRegex\n",
    "rclasses = [UpperRegex, LowerRegex, DigitRegex]\n",
    "series = email_addresses\n",
    "\n",
    "def get_class_stat(series, count_thres):\n",
    "    score_list = []\n",
    "    for rclass in rclasses:\n",
    "        cur_class_stat = score_single(rclass._base_regex, series, count_thres, rclass.n_possible)\n",
    "        if cur_class_stat[0] > 0:\n",
    "            score_list.append((rclass(), *cur_class_stat))\n",
    "    score_list.extend(LiteralRegex.get_candidates(series, count_thres))\n",
    "    return sorted(score_list, key=lambda res: -res[1])\n",
    "\n",
    "\n",
    "# cur_series = series\n",
    "count_thres = 5\n",
    "class_stat = get_class_stat(series, count_thres)\n",
    "cur_best_regex, best_score, cur_best_series = class_stat[0]\n",
    "cur_best_regex = OrRegex(cur_best_regex)\n",
    "\n",
    "for cur_regex, score, cur_series in class_stat[1:]:\n",
    "    if cur_best_regex.covers(cur_regex):\n",
    "        continue\n",
    "    cur_new_class_stat = get_class_stat(cur_series, count_thres)\n",
    "    best_new_class_stat = get_class_stat(cur_best_series, count_thres)\n",
    "\n",
    "    compatible = _check_stat_compatible(best_new_class_stat, cur_new_class_stat, count_thres)\n",
    "    if compatible:\n",
    "        if isinstance(cur_best_regex, OrRegex):\n",
    "            cur_best_regex.append(cur_regex)\n",
    "        else:\n",
    "            cur_best_regex = OrRegex(cur_best_regex, cur_regex)\n",
    "\n",
    "cur_series = series\n",
    "start_non_null = len(series) - series.null_count()\n",
    "cur_series = cur_best_regex.extract_after_first(series)\n",
    "i_start = None\n",
    "for cur_i in range(1, 100):\n",
    "    compatible = cur_best_regex.check_compatibility(cur_series, count_thres)\n",
    "    cur_non_null = len(cur_series) - cur_series.null_count()\n",
    "    if not compatible or cur_non_null < count_thres or cur_non_null < count_thres:\n",
    "        if i_start is None:\n",
    "            i_start = cur_i-1\n",
    "        i_end = cur_i-1\n",
    "        break\n",
    "    \n",
    "    if cur_non_null < start_non_null + count_thres:\n",
    "        i_start = cur_i\n",
    "    cur_series = cur_best_regex.extract_after_first(cur_series)\n",
    "\n",
    "print(i_start, i_end)\n",
    "print(cur_best_regex.regex)\n",
    "    # combi = OrRegex(cur_result[0], best_class_result[0])\n",
    "    # combi_class_stat = score_single(combi.regex, series, count_thres, combi.n_possible)\n",
    "    # combi_new_class_stat = get_class_stat(cur_result[2], count_thres)  \n",
    "    # print(f\"-----{cur_result[0].regex}---{compatible}---{best_class_result[0].covers(cur_result[0])}----\")\n",
    "# best_class_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2628bb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"../scripts/data/benchmark.json\") as handle:\n",
    "    bench_data = json.load(handle)\n",
    "with open(\"../scripts/data2/benchmark.json\") as handle:\n",
    "    bench_data_new = json.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd234099",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def _get_success_rate(fake_type, bench_data):\n",
    "    n_param = []\n",
    "    success = []\n",
    "    fails = []\n",
    "    # for var_data in bench_data.values():\n",
    "    for data in bench_data[fake_type].values():\n",
    "        n_param.extend(x[\"n_parameters\"] for x in data)\n",
    "        success.extend(x[\"success\"] for x in data)\n",
    "        fails.extend(x[\"failed\"] for x in data)\n",
    "\n",
    "    success_rate = np.array(success)/(np.array(fails)+np.array(success))\n",
    "    return np.array(n_param), success_rate\n",
    "\n",
    "def plot_succes_rate(fake_type):\n",
    "    plt.scatter(*_get_success_rate(fake_type, bench_data), label=\"old\")\n",
    "    plt.scatter(*_get_success_rate(fake_type, bench_data_new), label=\"new\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ec46b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_succes_rate(\"job\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda58230",
   "metadata": {},
   "outputs": [],
   "source": [
    "for url in email_addresses[:10]:\n",
    "    print(url, list(model.regex_edge.log_likelihood(url)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbcecd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_regex_from_list(regex_data):\n",
    "    if isinstance(regex_data, BaseRegex):\n",
    "        return regex_data.regex\n",
    "    if isinstance(regex_data, tuple):\n",
    "        optional_regex = [create_regex_from_list(rx) for rx in regex_data]\n",
    "        return r\"(\" + r\"|\".join(optional_regex) + \")\"\n",
    "    return \"\".join(create_regex_from_list(rx) for rx in regex_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf81a26",
   "metadata": {},
   "source": [
    "## Modeling the structured strings\n",
    "\n",
    "Now we will use the regexmodel package to model the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f49e44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # while cur_series.drop_nulls().len() > count_thres:\n",
    "        \n",
    "    # if result[\"score\"] < count_thres/len(series):\n",
    "    #     return [], []\n",
    "    # regex_list, count_list = fit_main_branch(result[\"new_series\"], count_thres=count_thres,\n",
    "    #                                          direction=direction)\n",
    "    # n_main_line = result[\"new_series\"].drop_nulls().len()\n",
    "    # n_alt_line = result[\"alt_series\"].drop_nulls().len()\n",
    "    # regex_list = [result[\"regex\"]] + regex_list\n",
    "    # count_list = [n_main_line] + count_list\n",
    "\n",
    "    # if len(result[\"alt_series\"].drop_nulls()) > count_thres and optionals:\n",
    "\n",
    "    #     regex_main = \"\".join(rx.regex for rx in regex_list)\n",
    "    #     res = result[\"alt_series\"].str.extract(r\"(^[\\S\\s]*?)\" + regex_main + r\"$\")\n",
    "    #     alt_regex_list, alt_count_list = fit_main_branch(res, count_thres, direction)\n",
    "    #     if len(alt_regex_list) > 0:\n",
    "    #         regex_list = [(alt_regex_list, [])] + regex_list\n",
    "    #         count_list = [(alt_count_list[-1], n_main_line)] + count_list\n",
    "\n",
    "    # return return_links\n",
    "    # # return regex_list, count_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c46269",
   "metadata": {},
   "outputs": [],
   "source": [
    "from regexmodel import RegexModel\n",
    "\n",
    "model = RegexModel.fit(email_addresses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f59f6b94",
   "metadata": {},
   "source": [
    "Let's first see how the good the model is by synthesizing new email addresses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d658b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "[model.draw() for _ in range(10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d9d942",
   "metadata": {},
   "source": [
    "While certainly not perfect, it certainly isn't so bad either, given that we have given the model only positive examples!\n",
    "\n",
    "Now let's look at the serialization of the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7821a86",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.serialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87953f7f",
   "metadata": {},
   "source": [
    "The serialization might seem overwhelming at first, but the first regex (`[a-z]{3,18}[0-9]{2,2}[@][a-z]{4,9}[\\\\\\\\.][c][o][m]`) is usually the most important one. We call this the main branch. On this main branch, there will be side branches, for example for \".info\" and \".biz\" email addresses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033eecb4",
   "metadata": {},
   "source": [
    "## Modeling performance\n",
    "\n",
    "There are also some modeling statistics that can be computed. Note that computing these can take a while depending on your computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d52d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit_statistics(email_addresses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8ce227",
   "metadata": {},
   "source": [
    "What the `fit_statistics` method does is to retrace back whether an email address that is given to it (e.g. johndoe@example.com) has a non-zero probability to be generated by the regex model. As we can see above, there were 18 email addresses in the list that have a probability of 0 to be generated by the model, while the overwhelming majority (982) can be generated with the fitted model.\n",
    "\n",
    "The value `n_parameters` gives the number of nodes in the model, and is thus an indicator of the complexity of the model. This is also correlated with the fit taking longer. We can influence this parameter during fitting by setting the `count_thres` parameter. If we set that threshold higher, we generally have a lower number of parameters and better performance.\n",
    "\n",
    "The statistic `avg_log_like_per_char` (average log-likelihood per character) shows how probable a value is on average per character. To understand this better, let's take a more simple example, where the regex is simply `\\d{2,2}`. For this regex, the log likelihood is simply log(1/10\\*1/10) = -2\\*log(10). Since all values have 2 characters, the average log-likelihood per character is -log(10) ~= 2.30. For failed values (values that cannot be generated by the model), we use a penalty score of -log(1000) per character.\n",
    "\n",
    "Ideally we want to have the lowest `n_parameters` (simplest model) with the highest `success` and the highest log-likelihood."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9fd48e",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f1fbae",
   "metadata": {},
   "source": [
    "To more clearly understand how the graph looks like, we can plot the regex model using the `regex_model_to_pyvis` function. To retrace the paths that can be taken, first find the start node and find the main branch.\n",
    "\n",
    "Note: PyVis doesnt work interactively in VSCode/Code OSS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da034fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from regexmodel.visualization import regex_model_to_pyvis\n",
    "\n",
    "net = regex_model_to_pyvis(model)\n",
    "net.show(\"regex.html\", notebook=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
